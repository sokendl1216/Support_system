#!/usr/bin/env python3
"""
Task 3-3a ãƒ¢ãƒ¼ãƒ‰åˆ¥çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–ã®ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import json
import logging
import sys
from pathlib import Path

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from ai.rag.rag_system import RAGSystem

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def load_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        config_path = Path(__file__).parent / "config" / "rag_config.json"
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è¿”ã™
        return {
            "embedding": {
                "model_name": "nomic-embed-text",
                "base_url": "http://localhost:11434",
                "batch_size": 32,
                "timeout": 30
            },
            "vector_store": {
                "dimension": 768,
                "metric": "cosine",
                "index_type": "Flat"
            },
            "knowledge_base": {
                "base_directory": "./knowledge_base",
                "chunk_size": 512,
                "chunk_overlap": 50,
                "file_extensions": [".txt", ".md", ".json"]
            },
            "retrieval": {
                "default_top_k": 5,
                "max_context_length": 4096,
                "default_similarity_threshold": 0.3
            },
            "mode_optimization": {
                "modes": {
                    "interactive": {
                        "similarity_threshold": 0.2,
                        "boost_user_context": 1.3,
                        "prefer_recent": True,
                        "personalization_weight": 0.2,
                        "response_speed_priority": True
                    },
                    "autonomous": {
                        "similarity_threshold": 0.15,
                        "exploration_factor": 1.4,
                        "cross_reference_boost": 1.2,
                        "multi_perspective_retrieval": True,
                        "depth_search_enabled": True
                    },
                    "hybrid": {
                        "similarity_threshold": 0.25,
                        "balanced_approach": True,
                        "adaptive_threshold": True,
                        "context_awareness": 0.6,
                        "exploration_factor": 1.2,
                        "boost_user_context": 1.1
                    },
                    "general": {
                        "similarity_threshold": 0.3,
                        "boost_user_context": 1.0,
                        "exploration_factor": 1.0
                    }
                }
            }
        }

async def test_mode_optimization():
    """ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–ã®ãƒ†ã‚¹ãƒˆ"""
    print("=== Task 3-3a ãƒ¢ãƒ¼ãƒ‰åˆ¥çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        config = await load_config()
        print("âœ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
        # RAGSystemã‚’åˆæœŸåŒ–
        rag_system = RAGSystem(config)
        print("âœ“ RAGSystemåˆæœŸåŒ–å®Œäº†")
        
        # åˆæœŸåŒ–
        await rag_system.initialize()
        print("âœ“ RAGSystemåˆæœŸåŒ–æˆåŠŸ")
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_query = "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹"
        
        print(f"\n--- ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: '{test_query}' ---")
        
        # å„ãƒ¢ãƒ¼ãƒ‰ã§ã®æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        modes = ["interactive", "autonomous", "hybrid", "general"]
        
        results = {}
        for mode in modes:
            print(f"\n{mode.upper()}ãƒ¢ãƒ¼ãƒ‰ã§ã®æ¤œç´¢:")
            try:
                search_results = await rag_system.search(test_query, mode=mode, top_k=3)
                
                print(f"  æ¤œç´¢çµæœæ•°: {len(search_results)}")
                
                if search_results:
                    # ãƒ¢ãƒ¼ãƒ‰è¨­å®šã‚’å–å¾—
                    mode_config = rag_system._get_mode_config(mode)
                    print(f"  é–¾å€¤: {mode_config.get('similarity_threshold', 'N/A')}")
                    print(f"  è¨­å®š: {mode_config}")
                    
                    for i, result in enumerate(search_results[:2]):  # ä¸Šä½2ä»¶ã®ã¿è¡¨ç¤º
                        print(f"    [{i+1}] é¡ä¼¼åº¦: {result.similarity:.3f}")
                        print(f"        ã‚½ãƒ¼ã‚¹: {result.chunk.source_file}")
                        print(f"        å†…å®¹(æŠœç²‹): {result.chunk.content[:100]}...")
                
                results[mode] = search_results
                print(f"  âœ“ {mode}ãƒ¢ãƒ¼ãƒ‰æ¤œç´¢å®Œäº†")
                
            except Exception as e:
                print(f"  âœ— {mode}ãƒ¢ãƒ¼ãƒ‰æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                results[mode] = []
        
        # çµæœã®æ¯”è¼ƒåˆ†æ
        print(f"\n--- ãƒ¢ãƒ¼ãƒ‰åˆ¥çµæœæ¯”è¼ƒ ---")
        for mode, mode_results in results.items():
            if mode_results:
                avg_similarity = sum(r.similarity for r in mode_results) / len(mode_results)
                print(f"{mode.upper()}: çµæœæ•°={len(mode_results)}, å¹³å‡é¡ä¼¼åº¦={avg_similarity:.3f}")
            else:
                print(f"{mode.upper()}: çµæœãªã—")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print(f"\n--- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ ---")
        context_result = await rag_system.generate_context(test_query, mode="interactive")
        print(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {context_result.get('context_length', 0)}")
        print(f"ã‚½ãƒ¼ã‚¹æ•°: {len(context_result.get('sources', []))}")
        if context_result.get('context'):
            print(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ(æŠœç²‹): {context_result['context'][:200]}...")
        
        # çµ±è¨ˆæƒ…å ±å–å¾—
        print(f"\n--- ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ ---")
        stats = await rag_system.get_stats()
        print(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {stats.get('system_status', 'unknown')}")
        if 'knowledge_base' in stats:
            kb_stats = stats['knowledge_base']
            print(f"æ–‡æ›¸æ•°: {kb_stats.get('total_documents', 0)}")
            print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {kb_stats.get('total_chunks', 0)}")
        
        print("\n=== Task 3-3a ãƒ†ã‚¹ãƒˆå®Œäº† ===")
        print("âœ“ ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        
        return True
        
    except Exception as e:
        print(f"\nâœ— ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    success = await test_mode_optimization()
    if success:
        print("\nğŸ‰ Task 3-3a ãƒ¢ãƒ¼ãƒ‰åˆ¥çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æœ€é©åŒ– - å®Ÿè£…å®Œäº†!")
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•— - å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„")
    
    return success

if __name__ == "__main__":
    asyncio.run(main())
