#!/usr/bin/env python3
"""
Ollamaçµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Task 3-1a ã®æœ€çµ‚ç¢ºèªç”¨
"""

import asyncio
import json
from pathlib import Path
from ai.providers.ollama_provider import OllamaProvider
from ai.llm_service import GenerationRequest, GenerationConfig

async def test_ollama_integration():
    print('=' * 50)
    print('ğŸš€ Ollamaçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹')
    print('=' * 50)
    
    try:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        config_path = Path('config/ollama_models.json')
        if not config_path.exists():
            print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
            return False
            
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {config_path}")
        
        # OllamaProviderã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        provider = OllamaProvider(model_config=config['models'])
        print("âœ… OllamaProvider ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆæˆåŠŸ")
        
        # 1. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        print("\nğŸ“Š ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")
        is_healthy = await provider.is_healthy()
        if is_healthy:
            print("âœ… Ollamaã‚µãƒ¼ãƒãƒ¼æ¥ç¶šæˆåŠŸ")
        else:
            print("âŒ Ollamaã‚µãƒ¼ãƒãƒ¼æ¥ç¶šå¤±æ•—")
            return False
        
        # 2. åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«å–å¾—
        print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«å–å¾—ä¸­...")
        models = await provider.get_available_models()
        print(f"âœ… åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«æ•°: {len(models)}")
        for i, model in enumerate(models, 1):
            print(f"   {i}. {model}")
        
        if not models:
            print("âŒ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        # 3. ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ†ã‚¹ãƒˆ
        print("\nğŸ¯ æœ€é©ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ†ã‚¹ãƒˆ...")
        selected = await provider._select_best_model()
        if selected:
            print(f"âœ… è‡ªå‹•é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {selected}")
        else:
            print("âŒ ãƒ¢ãƒ‡ãƒ«é¸æŠã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # 4. ç°¡å˜ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("\nğŸ’¬ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ...")
        request = GenerationRequest(
            prompt="Hello, how are you?",
            config=GenerationConfig(
                max_tokens=50,
                temperature=0.7
            )
        )
        
        response = await provider.generate(request)
        if response.error:
            print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {response.error}")
            return False
        else:
            print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆæˆåŠŸ")
            print(f"   ãƒ¢ãƒ‡ãƒ«: {response.model_name}")
            print(f"   ç”Ÿæˆæ™‚é–“: {response.generation_time:.2f}ç§’")
            print(f"   ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {response.token_count}")
            print(f"   ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ: {response.text[:100]}{'...' if len(response.text) > 100 else ''}")
        
        # 5. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        print("\nğŸ” è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ...")
        for config_name in config['models']:
            actual_model = await provider._find_actual_model_name(config_name)
            if actual_model:
                print(f"   âœ… {config_name} -> {actual_model}")
            else:
                print(f"   âš ï¸  {config_name} -> ãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•—ï¼ˆãƒ¢ãƒ‡ãƒ«æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")
        
        print('\n' + '=' * 50)
        print('ğŸ‰ Ollamaçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†ï¼ã™ã¹ã¦æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™')
        print('âœ… Task 3-1a (Ollama Installation & Setup) å®Œäº†ç¢ºèª')
        print('=' * 50)
        return True
        
    except Exception as e:
        print(f"\nâŒ çµ±åˆãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(test_ollama_integration())
    if success:
        print("\nğŸš€ æ¬¡ã®ã‚¿ã‚¹ã‚¯ã«é€²ã‚€æº–å‚™ãŒã§ãã¾ã—ãŸï¼")
    else:
        print("\nâš ï¸  å•é¡Œã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰æ¬¡ã®ã‚¿ã‚¹ã‚¯ã«é€²ã‚“ã§ãã ã•ã„")
