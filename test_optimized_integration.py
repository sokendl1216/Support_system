#!/usr/bin/env python3
"""
æœ€é©åŒ–ã•ã‚ŒãŸAIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆãƒ†ã‚¹ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ä¿®æ­£ã•ã‚ŒãŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ãŒ
å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§æ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
"""

import asyncio
import logging
import sys
import time
from pathlib import Path

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# é«˜æ€§èƒ½ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ai.high_performance_cache_manager import HighPerformanceAICacheManager

async def test_basic_operations():
    """åŸºæœ¬çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥æ“ä½œã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== åŸºæœ¬æ“ä½œãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    cache_dir = "./test_integration_cache"
    cache_manager = HighPerformanceAICacheManager(
        cache_dir=cache_dir,
        ttl_seconds=3600,
        enable_cache=True,
        use_similarity=True
    )
    
    # åˆæœŸåŒ–å®Œäº†ã‚’å¾…æ©Ÿ
    if hasattr(cache_manager, '_initialization_task') and cache_manager._initialization_task:
        await asyncio.wait_for(cache_manager._initialization_task, timeout=10)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_queries = [
        "Pythonã§ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã¯ï¼Ÿ",
        "æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬æ¦‚å¿µã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–æ‰‹æ³•ã«ã¤ã„ã¦",
        "APIã®è¨­è¨ˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
        "Pythonã‚’ä½¿ã£ãŸã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™º",  # é¡ä¼¼ã‚¯ã‚¨ãƒª
    ]
    
    test_results = [
        {"answer": "Pythonã§ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚’ä½œæˆã™ã‚‹ã«ã¯ã€Flaskã‚„Djangoãªã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™...", "tokens": 150},
        {"answer": "æ©Ÿæ¢°å­¦ç¿’ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹AIæŠ€è¡“ã§ã™...", "tokens": 200},
        {"answer": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–ã«ã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã€ã‚¯ã‚¨ãƒªæœ€é©åŒ–ãªã©ãŒã‚ã‚Šã¾ã™...", "tokens": 180},
        {"answer": "APIè¨­è¨ˆã§ã¯ã€RESTfulåŸå‰‡ã«å¾“ã„ã€é©åˆ‡ãªHTTPãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™...", "tokens": 170},
    ]
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ãƒ†ã‚¹ãƒˆ
    logger.info("1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›¸ãè¾¼ã¿ãƒ†ã‚¹ãƒˆ")
    for i, (query, result) in enumerate(zip(test_queries[:4], test_results)):
        key_data = {"query": query, "model": "test-model"}
        
        start_time = time.time()
        await cache_manager.set_cache(key_data, result)
        elapsed = time.time() - start_time
        
        logger.info(f"   ã‚¯ã‚¨ãƒª{i+1}ä¿å­˜å®Œäº†: {elapsed:.4f}ç§’")
    
    # 2. å®Œå…¨ä¸€è‡´æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    logger.info("2. å®Œå…¨ä¸€è‡´æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    for i, query in enumerate(test_queries[:4]):
        key_data = {"query": query, "model": "test-model"}
        
        start_time = time.time()
        hit, result = await cache_manager.get_cache(key_data)
        elapsed = time.time() - start_time
        
        if hit:
            logger.info(f"   ã‚¯ã‚¨ãƒª{i+1}ãƒ’ãƒƒãƒˆ: {elapsed:.4f}ç§’")
        else:
            logger.warning(f"   ã‚¯ã‚¨ãƒª{i+1}ãƒŸã‚¹: {elapsed:.4f}ç§’")
      # 3. é¡ä¼¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    logger.info("3. é¡ä¼¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    similar_query = test_queries[4]  # é¡ä¼¼ã‚¯ã‚¨ãƒª
    key_data = {"query": similar_query, "model": "test-model"}
    
    start_time = time.time()
    hit, result = await cache_manager.get_cache(key_data)
    elapsed = time.time() - start_time
    
    if hit:
        logger.info(f"   é¡ä¼¼ã‚¯ã‚¨ãƒªãƒ’ãƒƒãƒˆ: {elapsed:.4f}ç§’")
        if result:
            logger.info(f"   çµæœ: {result.get('answer', 'N/A')[:50]}...")
        else:
            logger.info("   çµæœ: None")
    else:
        logger.warning(f"   é¡ä¼¼ã‚¯ã‚¨ãƒªãƒŸã‚¹: {elapsed:.4f}ç§’")
    
    # 4. çµ±è¨ˆæƒ…å ±ã®ç¢ºèª
    logger.info("4. çµ±è¨ˆæƒ…å ±ç¢ºèª")
    stats = await cache_manager.get_stats()
    logger.info(f"   ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {stats.get('total_requests', 0)}")
    logger.info(f"   å®Œå…¨ä¸€è‡´ãƒ’ãƒƒãƒˆæ•°: {stats.get('hits', 0)}")
    logger.info(f"   ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°: {stats.get('memory_hits', 0)}")
    logger.info(f"   é¡ä¼¼æ¤œç´¢ãƒ’ãƒƒãƒˆæ•°: {stats.get('similarity_hits', 0)}")
    logger.info(f"   ç·ãƒ’ãƒƒãƒˆç‡: {stats.get('hit_ratio', 0):.2%}")
    
    return True

async def test_concurrent_operations():
    """ä¸¦è¡Œå‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("\n=== ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    cache_manager = HighPerformanceAICacheManager(
        cache_dir="./test_concurrent_cache",
        ttl_seconds=3600,
        enable_cache=True,
        use_similarity=True
    )
    
    # åˆæœŸåŒ–å®Œäº†ã‚’å¾…æ©Ÿ
    if hasattr(cache_manager, '_initialization_task') and cache_manager._initialization_task:
        await asyncio.wait_for(cache_manager._initialization_task, timeout=10)
    
    # ä¸¦è¡Œæ›¸ãè¾¼ã¿ãƒ†ã‚¹ãƒˆ
    concurrent_queries = [
        f"ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª{i}: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®ç‰¹å¾´ã«ã¤ã„ã¦" for i in range(10)
    ]
    concurrent_results = [
        {"answer": f"å›ç­”{i}: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ã¯å¤šæ§˜ãªç‰¹å¾´ãŒã‚ã‚Šã¾ã™...", "tokens": 100 + i * 10}
        for i in range(10)
    ]
    
    # ä¸¦è¡Œæ›¸ãè¾¼ã¿
    start_time = time.time()
    write_tasks = []
    for query, result in zip(concurrent_queries, concurrent_results):
        key_data = {"query": query, "model": "test-model"}
        task = cache_manager.set_cache(key_data, result)
        write_tasks.append(task)
    
    await asyncio.gather(*write_tasks)
    write_time = time.time() - start_time
    logger.info(f"ä¸¦è¡Œæ›¸ãè¾¼ã¿å®Œäº†: {write_time:.3f}ç§’ ({len(concurrent_queries)}ã‚¯ã‚¨ãƒª)")
    
    # ä¸¦è¡Œèª­ã¿è¾¼ã¿
    start_time = time.time()
    read_tasks = []
    for query in concurrent_queries:
        key_data = {"query": query, "model": "test-model"}
        task = cache_manager.get_cache(key_data)
        read_tasks.append(task)
    
    results = await asyncio.gather(*read_tasks)
    read_time = time.time() - start_time
    hits = sum(1 for hit, _ in results if hit)
    
    logger.info(f"ä¸¦è¡Œèª­ã¿è¾¼ã¿å®Œäº†: {read_time:.3f}ç§’ ({hits}/{len(concurrent_queries)}ãƒ’ãƒƒãƒˆ)")
    
    return True

async def test_error_handling():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("\n=== ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    cache_manager = HighPerformanceAICacheManager(
        cache_dir="./test_error_cache",
        ttl_seconds=3600,
        enable_cache=True,
        use_similarity=True
    )
    
    # åˆæœŸåŒ–å®Œäº†ã‚’å¾…æ©Ÿ
    if hasattr(cache_manager, '_initialization_task') and cache_manager._initialization_task:
        await asyncio.wait_for(cache_manager._initialization_task, timeout=10)
    
    try:
        # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ
        invalid_key = None
        hit, result = await cache_manager.get_cache(invalid_key)
        logger.info("ä¸æ­£ãªã‚­ãƒ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†: æ­£å¸¸ã«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
    except Exception as e:
        logger.info(f"ä¸æ­£ãªã‚­ãƒ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†: ã‚¨ãƒ©ãƒ¼æ­£å¸¸æ¤œå‡º - {type(e).__name__}")
    
    try:
        # ç©ºã®ã‚¯ã‚¨ãƒªã§ã®ãƒ†ã‚¹ãƒˆ
        empty_key = {"query": "", "model": "test-model"}
        hit, result = await cache_manager.get_cache(empty_key)
        logger.info("ç©ºã®ã‚¯ã‚¨ãƒªå‡¦ç†: æ­£å¸¸ã«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
    except Exception as e:
        logger.info(f"ç©ºã®ã‚¯ã‚¨ãƒªå‡¦ç†: ã‚¨ãƒ©ãƒ¼æ­£å¸¸æ¤œå‡º - {type(e).__name__}")
    
    return True

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        logger.info("ğŸš€ æœ€é©åŒ–ã•ã‚ŒãŸAIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ  çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # åŸºæœ¬æ“ä½œãƒ†ã‚¹ãƒˆ
        success1 = await test_basic_operations()
        
        # ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆ  
        success2 = await test_concurrent_operations()
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        success3 = await test_error_handling()
        
        if success1 and success2 and success3:
            logger.info("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            logger.info("ğŸ‰ æœ€é©åŒ–ã•ã‚ŒãŸAIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        else:
            logger.error("\nâŒ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        logger.error(f"çµ±åˆãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main())
