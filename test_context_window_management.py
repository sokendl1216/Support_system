#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Task 3-4: Context Window Management ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã€A/Bãƒ†ã‚¹ãƒˆåŸºç›¤ã®æ¤œè¨¼

æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ:
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†
- é€²è¡Œãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–
- RAGçµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
- A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†
"""

import asyncio
import sys
import os
import logging
import json
import time
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from ai.rag.rag_system import RAGSystem
from ai.prompts.prompt_template_manager import (
    PromptTemplateManager, TemplateType, PromptMode
)
from ai.prompts.integrated_prompt_service import (
    IntegratedPromptService, ContextOptimizationConfig
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config(config_path: str) -> dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}


async def test_template_manager():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        template_manager = PromptTemplateManager("ai/prompts/templates")
        
        # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        stats = template_manager.get_stats()
        logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçµ±è¨ˆ: {stats}")
        
        # æ–°ã—ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆãƒ†ã‚¹ãƒˆ
        test_template_id = template_manager.create_template(
            name="test_template",
            template="ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {query}\nå‚è€ƒ: {context}\nå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
            template_type=TemplateType.USER,
            mode=PromptMode.INTERACTIVE,
            description="ãƒ†ã‚¹ãƒˆç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
            author="test"
        )
        logger.info(f"ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ: {test_template_id}")
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—ãƒ†ã‚¹ãƒˆ
        template = template_manager.get_template(test_template_id)
        if template:
            logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—æˆåŠŸ: {template.metadata.name}")
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        variables = {
            "query": "Python ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ï¼Ÿ",
            "context": "Python ã¯èª­ã¿ã‚„ã™ãã€åŠ¹ç‡çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚"
        }
        
        rendered = template_manager.render_template(
            test_template_id,
            variables,
            mode=PromptMode.INTERACTIVE
        )
        logger.info(f"ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çµæœ:\n{rendered}")
        
        # A/Bãƒ†ã‚¹ãƒˆãƒãƒªã‚¢ãƒ³ãƒˆä½œæˆ
        variant_id = template_manager.create_ab_variant(
            test_template_id,
            "æ”¹è‰¯ç‰ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {query}\n\næƒ…å ±: {context}\n\nè©³ç´°ã«å›ç­”ã—ã¾ã™ã€‚",
            weight=0.5
        )
        logger.info(f"A/Bãƒãƒªã‚¢ãƒ³ãƒˆä½œæˆ: {variant_id}")
        
        logger.info("âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ãƒ†ã‚¹ãƒˆå®Œäº†")
        return template_manager
        
    except Exception as e:
        logger.error(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        raise


async def test_integrated_prompt_service():
    """çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        config_path = os.path.join(project_root, "config", "rag_config.json")
        config = load_config(config_path)
        if not config:
            logger.warning("RAGè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åŸºæœ¬è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            config = {
                "embedding": {"model_name": "nomic-embed-text"},
                "vector_store": {"dimension": 768},
                "knowledge_base": {"base_path": "ai/rag/knowledge_base"},
                "retrieval": {"top_k": 5, "similarity_threshold": 0.5}
            }
        
        rag_system = RAGSystem(config)
        if not await rag_system.initialize():
            logger.warning("RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã®ã¿ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚")
            rag_system = None
        
        # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        prompt_service = IntegratedPromptService(rag_system)
        
        # ã‚µãƒ¼ãƒ“ã‚¹çµ±è¨ˆè¡¨ç¤º
        service_stats = prompt_service.get_service_stats()
        logger.info(f"ã‚µãƒ¼ãƒ“ã‚¹çµ±è¨ˆ: {json.dumps(service_stats, ensure_ascii=False, indent=2)}")
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_queries = [
            "Python ã§ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "Web ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã«ã¤ã„ã¦",
            "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„"
        ]
        
        # å„ãƒ¢ãƒ¼ãƒ‰ã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
        for mode in [PromptMode.INTERACTIVE, PromptMode.AUTONOMOUS, PromptMode.HYBRID]:
            logger.info(f"\n--- {mode.value.upper()}ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ ---")
            
            for query in test_queries[:1]:  # 1ã¤ã®ã‚¯ã‚¨ãƒªã§ãƒ†ã‚¹ãƒˆ
                logger.info(f"ã‚¯ã‚¨ãƒª: {query}")
                
                # ãƒ¢ãƒ¼ãƒ‰æœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                result = await prompt_service.generate_mode_optimized_prompt(
                    query=query,
                    mode=mode
                )
                
                logger.info(f"ç”Ÿæˆæ™‚é–“: {result.generation_time:.3f}ç§’")
                logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆID: {result.template_id}")
                logger.info(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {result.context_length}")
                logger.info(f"RAGçµæœæ•°: {result.rag_results_count}")
                logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(result.prompt)} æ–‡å­—")
                logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰:\n{result.prompt[:200]}...")
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                prompt_service.template_manager.record_performance(
                    result.template_id,
                    result.variant_id,
                    {"response_quality": 0.85, "task_completion": 0.80},
                    result.generation_time
                )
        
        logger.info("âœ… çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†")
        return prompt_service
        
    except Exception as e:
        logger.error(f"âŒ çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        raise


async def test_context_window_management():
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        from ai.prompts.prompt_template_manager import ContextWindowManager
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        context_manager = ContextWindowManager(max_tokens=4000)
        
        # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æº–å‚™
        long_components = [
            ("ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤º", "ã‚ãªãŸã¯å°‚é–€çš„ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚" * 100, 1),
            ("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª", "è©³ç´°ãªè³ªå•å†…å®¹ã§ã™ã€‚" * 200, 2),
            ("RAGæƒ…å ±", "æ¤œç´¢ã•ã‚ŒãŸé–¢é€£æƒ…å ±ã§ã™ã€‚" * 500, 3),
            ("è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ", "è£œè¶³æƒ…å ±ã§ã™ã€‚" * 300, 4)
        ]
        
        logger.info("å…ƒã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:")
        total_chars = 0
        for name, text, priority in long_components:
            estimated_tokens = context_manager.estimate_tokens(text)
            total_chars += len(text)
            logger.info(f"  {name}: {len(text)} æ–‡å­—, æ¨å®š {estimated_tokens} ãƒˆãƒ¼ã‚¯ãƒ³")
        
        logger.info(f"åˆè¨ˆæ–‡å­—æ•°: {total_chars}")
        logger.info(f"åˆè¨ˆæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³: {context_manager.estimate_tokens(''.join(t[1] for t in long_components))}")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«åã‚ã‚‹
        fitted_components = context_manager.fit_context(long_components)
        
        logger.info("èª¿æ•´å¾Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:")
        fitted_total_chars = 0
        for name, text in fitted_components:
            estimated_tokens = context_manager.estimate_tokens(text)
            fitted_total_chars += len(text)
            logger.info(f"  {name}: {len(text)} æ–‡å­—, æ¨å®š {estimated_tokens} ãƒˆãƒ¼ã‚¯ãƒ³")
        
        logger.info(f"èª¿æ•´å¾Œåˆè¨ˆæ–‡å­—æ•°: {fitted_total_chars}")
        logger.info(f"èª¿æ•´å¾Œæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³: {context_manager.estimate_tokens(''.join(t[1] for t in fitted_components))}")
        
        # åˆ¶é™å†…ã«åã¾ã£ãŸã‹ãƒã‚§ãƒƒã‚¯
        total_tokens = sum(context_manager.estimate_tokens(text) for _, text in fitted_components)
        if total_tokens <= context_manager.available_tokens:
            logger.info("âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ¶é™å†…ã«æ­£å¸¸ã«åã¾ã‚Šã¾ã—ãŸ")
        else:
            logger.warning(f"âš ï¸ åˆ¶é™ã‚’è¶…é: {total_tokens} > {context_manager.available_tokens}")
        
        logger.info("âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        raise


async def test_ab_testing_framework():
    """A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        config = {
            "embedding": {"model_name": "nomic-embed-text"},
            "vector_store": {"dimension": 768},
            "knowledge_base": {"base_path": "ai/rag/knowledge_base"}
        }
        
        rag_system = RAGSystem(config)
        prompt_service = IntegratedPromptService(rag_system)
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        template_manager = prompt_service.template_manager
        
        # é©å¿œå‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§A/Bãƒ†ã‚¹ãƒˆ
        adaptive_templates = [
            t for t in template_manager.templates.values()
            if t.metadata.mode == PromptMode.HYBRID
        ]
        
        if adaptive_templates:
            template_id = adaptive_templates[0].metadata.template_id
            logger.info(f"A/Bãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {template_id}")
            
            # A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆçŸ­æ™‚é–“ç‰ˆï¼‰
            test_results = await prompt_service.run_ab_test(
                query="Webé–‹ç™ºã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
                mode=PromptMode.HYBRID,
                template_id=template_id,
                test_duration_minutes=1,  # 1åˆ†é–“ã®çŸ­ç¸®ãƒ†ã‚¹ãƒˆ
                sample_size=10
            )
            
            logger.info("A/Bãƒ†ã‚¹ãƒˆçµæœ:")
            logger.info(f"  ãƒ†ã‚¹ãƒˆæœŸé–“: {test_results['test_duration']:.1f}ç§’")
            logger.info(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {test_results['sample_count']}")
            
            # çµæœè©³ç´°
            for template_type, metrics in test_results['results'].items():
                logger.info(f"  {template_type}:")
                logger.info(f"    ä½¿ç”¨å›æ•°: {metrics['usage_count']}")
                logger.info(f"    æˆåŠŸå›æ•°: {metrics['success_count']}")
                if metrics['usage_count'] > 0:
                    success_rate = metrics['success_count'] / metrics['usage_count']
                    avg_time = metrics['total_time'] / metrics['usage_count']
                    logger.info(f"    æˆåŠŸç‡: {success_rate:.2%}")
                    logger.info(f"    å¹³å‡æ™‚é–“: {avg_time:.3f}ç§’")
            
            # åˆ†æçµæœ
            analysis = test_results['analysis']
            logger.info(f"çµ±è¨ˆçš„æœ‰æ„æ€§: {analysis['statistical_significance']}")
            if analysis['recommendations']:
                logger.info(f"æ¨å¥¨äº‹é …: {analysis['recommendations']}")
            
        else:
            logger.warning("A/Bãƒ†ã‚¹ãƒˆç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        logger.info("âœ… A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        # A/Bãƒ†ã‚¹ãƒˆã¯è¤‡é›‘ãªã®ã§ã€ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶™ç¶š


async def test_mode_specific_optimization():
    """ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–ã®è©³ç´°ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–è©³ç´°ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # ç°¡æ˜“RAGã‚·ã‚¹ãƒ†ãƒ è¨­å®š
        config = {
            "embedding": {"model_name": "nomic-embed-text"},
            "vector_store": {"dimension": 768}
        }
        rag_system = RAGSystem(config)
        prompt_service = IntegratedPromptService(rag_system)
        
        test_query = "åŠ¹ç‡çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ‰‹æ³•ã«ã¤ã„ã¦"
        
        # å„ãƒ¢ãƒ¼ãƒ‰ã®æœ€é©åŒ–è¨­å®šã‚’æ¯”è¼ƒ
        optimization_configs = {
            PromptMode.INTERACTIVE: ContextOptimizationConfig(
                max_context_length=3000,
                rag_results_limit=3,
                prioritize_recent=True,
                include_metadata=False
            ),
            PromptMode.AUTONOMOUS: ContextOptimizationConfig(
                max_context_length=6000,
                rag_results_limit=8,
                prioritize_recent=False,
                include_metadata=True
            ),
            PromptMode.HYBRID: ContextOptimizationConfig(
                max_context_length=4500,
                rag_results_limit=5,
                prioritize_recent=True,
                include_metadata=True
            )
        }
        
        logger.info("ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–è¨­å®š:")
        for mode, config in optimization_configs.items():
            logger.info(f"  {mode.value}:")
            logger.info(f"    æœ€å¤§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {config.max_context_length}")
            logger.info(f"    RAGçµæœåˆ¶é™: {config.rag_results_limit}")
            logger.info(f"    æœ€è¿‘å„ªå…ˆ: {config.prioritize_recent}")
            logger.info(f"    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å«ã‚€: {config.include_metadata}")
        
        # å„ãƒ¢ãƒ¼ãƒ‰ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã—ã¦æ¯”è¼ƒ
        results = {}
        for mode in [PromptMode.INTERACTIVE, PromptMode.AUTONOMOUS, PromptMode.HYBRID]:
            result = await prompt_service.generate_prompt(
                query=test_query,
                mode=mode,
                optimization_config=optimization_configs[mode],
                use_rag=False  # RAGãªã—ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é•ã„ã‚’ç¢ºèª
            )
            results[mode] = result
            
            logger.info(f"\n{mode.value}ãƒ¢ãƒ¼ãƒ‰çµæœ:")
            logger.info(f"  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(result.prompt)} æ–‡å­—")
            logger.info(f"  ç”Ÿæˆæ™‚é–“: {result.generation_time:.3f}ç§’")
            logger.info(f"  ä½¿ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {result.metadata['template_name']}")
        
        # çµæœæ¯”è¼ƒ
        logger.info("\nçµæœæ¯”è¼ƒ:")
        for mode, result in results.items():
            prompt_words = len(result.prompt.split())
            logger.info(f"  {mode.value}: {len(result.prompt)}æ–‡å­—, {prompt_words}èª, {result.generation_time:.3f}ç§’")
        
        logger.info("âœ… ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–è©³ç´°ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–è©³ç´°ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        raise


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    logger.info("ğŸš€ Task 3-4: Context Window Management ãƒ†ã‚¹ãƒˆé–‹å§‹")
    logger.info("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã€A/Bãƒ†ã‚¹ãƒˆåŸºç›¤ã®æ¤œè¨¼")
    
    try:
        # 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ãƒ†ã‚¹ãƒˆ
        template_manager = await test_template_manager()
        
        # 2. çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ
        prompt_service = await test_integrated_prompt_service()
        
        # 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ãƒ†ã‚¹ãƒˆ
        await test_context_window_management()
        
        # 4. ãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–è©³ç´°ãƒ†ã‚¹ãƒˆ
        await test_mode_specific_optimization()
        
        # 5. A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
        await test_ab_testing_framework()
        
        # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
        logger.info("\n=== æœ€çµ‚çµ±è¨ˆæƒ…å ± ===")
        if prompt_service:
            final_stats = prompt_service.get_service_stats()
            logger.info("çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚µãƒ¼ãƒ“ã‚¹çµ±è¨ˆ:")
            logger.info(f"  ç·ç”Ÿæˆå›æ•°: {final_stats['prompt_service']['total_generations']}")
            logger.info(f"  æˆåŠŸç”Ÿæˆå›æ•°: {final_stats['prompt_service']['successful_generations']}")
            logger.info(f"  å¹³å‡ç”Ÿæˆæ™‚é–“: {final_stats['prompt_service']['average_generation_time']:.3f}ç§’")
            
            template_stats = final_stats['template_manager']
            logger.info("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†çµ±è¨ˆ:")
            logger.info(f"  ç·ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: {template_stats['total_templates']}")
            logger.info(f"  ç·ãƒãƒªã‚¢ãƒ³ãƒˆæ•°: {template_stats['total_variants']}")
            logger.info(f"  A/Bãƒ†ã‚¹ãƒˆæœ‰åŠ¹: {template_stats['ab_test_enabled']}")
        
        logger.info("ğŸ‰ Task 3-4: Context Window Management ãƒ†ã‚¹ãƒˆå®Œäº†")
        logger.info("âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Task 3-4 ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
