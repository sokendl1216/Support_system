"""
Enhanced Program Generator Service - AIçµ±åˆå¼·åŒ–ç‰ˆ

ãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ã«OllamaProviderçµ±åˆã€é«˜åº¦ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã€
ã‚³ãƒ¼ãƒ‰å“è³ªæ¤œè¨¼ã€è‡ªå‹•æœ€é©åŒ–æ©Ÿèƒ½ã‚’è¿½åŠ ã—ãŸå¼·åŒ–ç‰ˆå®Ÿè£…
"""

import asyncio
import logging
import re
import ast
import json
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from pathlib import Path

from core.dependency_injection import injectable
from data.models.job import JobInput, JobOutput, GenerationResult
from ai.providers.ollama_provider import OllamaProvider
from ai.rag.rag_system import RAGSystem
from ai.prompts.prompt_template_manager import PromptTemplateManager
from services.program_generator.base import BaseProgramGenerator

logger = logging.getLogger(__name__)


class CodeQualityMetrics:
    """ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    
    def __init__(self):
        self.complexity_score = 0.0
        self.readability_score = 0.0
        self.maintainability_score = 0.0
        self.error_probability = 0.0
        self.suggestions = []
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "complexity_score": self.complexity_score,
            "readability_score": self.readability_score,
            "maintainability_score": self.maintainability_score,
            "error_probability": self.error_probability,
            "suggestions": self.suggestions
        }


class EnhancedCodeAnalyzer:
    """å¼·åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰è§£ææ©Ÿèƒ½"""
    
    def __init__(self):
        self.language_patterns = {
            'python': {
                'import_pattern': r'^(?:import|from)\s+([a-zA-Z_][a-zA-Z0-9_]*)',
                'function_pattern': r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(',
                'class_pattern': r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*[\(\:]:',
                'comment_pattern': r'#.*$'
            },
            'javascript': {
                'import_pattern': r'(?:import|require)\s*\(["\']([^"\']+)["\']',
                'function_pattern': r'(?:function\s+([a-zA-Z_][a-zA-Z0-9_]*)|([a-zA-Z_][a-zA-Z0-9_]*)\s*=\s*(?:function|\([^)]*\)\s*=>))',
                'class_pattern': r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)',
                'comment_pattern': r'//.*$|/\*.*?\*/'
            }
        }
    
    async def analyze_code_quality(self, code: str, language: str) -> CodeQualityMetrics:
        """ã‚³ãƒ¼ãƒ‰å“è³ªã‚’è©³ç´°åˆ†æ"""
        metrics = CodeQualityMetrics()
        
        try:
            # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            lines = code.split('\n')
            non_empty_lines = [line for line in lines if line.strip()]
            
            # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
            metrics.complexity_score = await self._calculate_complexity(code, language)
            
            # å¯èª­æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
            metrics.readability_score = await self._calculate_readability(code, language)
            
            # ä¿å®ˆæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
            metrics.maintainability_score = await self._calculate_maintainability(code, language)
            
            # ã‚¨ãƒ©ãƒ¼äºˆæ¸¬ç¢ºç‡
            metrics.error_probability = await self._predict_error_probability(code, language)
            
            # æ”¹å–„ææ¡ˆç”Ÿæˆ
            metrics.suggestions = await self._generate_suggestions(code, language, metrics)
            
            logger.info(f"ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æå®Œäº†: è¤‡é›‘åº¦={metrics.complexity_score:.2f}, å¯èª­æ€§={metrics.readability_score:.2f}")
            
        except Exception as e:
            logger.error(f"ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            metrics.complexity_score = 5.0
            metrics.readability_score = 7.0
            metrics.maintainability_score = 6.0
            metrics.error_probability = 0.3
        
        return metrics
    
    async def _calculate_complexity(self, code: str, language: str) -> float:
        """å¾ªç’°çš„è¤‡é›‘åº¦ã‚’è¨ˆç®—"""
        try:
            if language == 'python':
                return await self._python_complexity(code)
            elif language == 'javascript':
                return await self._javascript_complexity(code)
            else:
                return await self._generic_complexity(code)
        except Exception:
            return 5.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    async def _python_complexity(self, code: str) -> float:
        """Pythonå›ºæœ‰ã®è¤‡é›‘åº¦è¨ˆç®—"""
        try:
            tree = ast.parse(code)
            complexity = 1  # åŸºæœ¬ãƒ‘ã‚¹
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.If, ast.While, ast.For)):
                    complexity += 1
                elif isinstance(node, ast.ExceptHandler):
                    complexity += 1
                elif isinstance(node, ast.Lambda):
                    complexity += 1
            
            return min(complexity, 10.0)
        except:
            return 5.0
    
    async def _javascript_complexity(self, code: str) -> float:
        """JavaScriptå›ºæœ‰ã®è¤‡é›‘åº¦è¨ˆç®—"""
        complexity = 1
        
        # åˆ¶å¾¡æ§‹é€ ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        patterns = [
            r'\bif\s*\(',
            r'\bwhile\s*\(',
            r'\bfor\s*\(',
            r'\bswitch\s*\(',
            r'\bcatch\s*\(',
            r'\?\s*.*?\s*:'  # ä¸‰é …æ¼”ç®—å­
        ]
        
        for pattern in patterns:
            complexity += len(re.findall(pattern, code))
        
        return min(complexity, 10.0)
    
    async def _generic_complexity(self, code: str) -> float:
        """æ±ç”¨çš„ãªè¤‡é›‘åº¦è¨ˆç®—"""
        lines = code.split('\n')
        complexity = len([line for line in lines if any(keyword in line for keyword in ['if', 'while', 'for', 'switch', 'case'])])
        return min(complexity + 1, 10.0)
    
    async def _calculate_readability(self, code: str, language: str) -> float:
        """å¯èª­æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 10.0
        lines = code.split('\n')
        
        # å¹³å‡è¡Œé•·ãƒã‚§ãƒƒã‚¯
        avg_line_length = sum(len(line) for line in lines) / max(len(lines), 1)
        if avg_line_length > 120:
            score -= 2.0
        elif avg_line_length > 80:
            score -= 1.0
        
        # ã‚³ãƒ¡ãƒ³ãƒˆç‡ãƒã‚§ãƒƒã‚¯
        comment_lines = 0
        for line in lines:
            if language == 'python' and line.strip().startswith('#'):
                comment_lines += 1
            elif language == 'javascript' and (line.strip().startswith('//') or '/*' in line):
                comment_lines += 1
        
        comment_ratio = comment_lines / max(len(lines), 1)
        if comment_ratio < 0.1:
            score -= 1.5
        
        # ãƒã‚¹ãƒˆæ·±åº¦ãƒã‚§ãƒƒã‚¯
        max_indent = 0
        for line in lines:
            indent = len(line) - len(line.lstrip())
            max_indent = max(max_indent, indent)
        
        if max_indent > 20:
            score -= 2.0
        elif max_indent > 12:
            score -= 1.0
        
        return max(score, 0.0)
    
    async def _calculate_maintainability(self, code: str, language: str) -> float:
        """ä¿å®ˆæ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 10.0
        
        # é–¢æ•°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if language == 'python':
            functions = re.findall(r'def\s+\w+.*?(?=\ndef|\nclass|\Z)', code, re.DOTALL)
        else:
            functions = re.findall(r'function\s+\w+.*?{.*?}', code, re.DOTALL)
        
        for func in functions:
            func_lines = len(func.split('\n'))
            if func_lines > 50:
                score -= 1.0
            elif func_lines > 30:
                score -= 0.5
        
        # é‡è¤‡ã‚³ãƒ¼ãƒ‰æ¤œå‡º
        lines = [line.strip() for line in code.split('\n') if line.strip()]
        unique_lines = set(lines)
        duplicate_ratio = 1 - (len(unique_lines) / max(len(lines), 1))
        
        if duplicate_ratio > 0.3:
            score -= 2.0
        elif duplicate_ratio > 0.2:
            score -= 1.0
        
        return max(score, 0.0)
    
    async def _predict_error_probability(self, code: str, language: str) -> float:
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç¢ºç‡ã‚’äºˆæ¸¬"""
        error_indicators = 0
        
        # ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
        error_patterns = [
            r'TODO|FIXME|XXX',  # æœªå®Œæˆãƒãƒ¼ã‚«ãƒ¼
            r'print\s*\(',      # ãƒ‡ãƒãƒƒã‚°æ–‡
            r'console\.log',    # ãƒ‡ãƒãƒƒã‚°æ–‡
            r'//\s*hack',       # ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆ
            r'#\s*hack',        # ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆ
        ]
        
        for pattern in error_patterns:
            error_indicators += len(re.findall(pattern, code, re.IGNORECASE))
        
        # è¤‡é›‘ãªæ­£è¦è¡¨ç¾ã‚„æ–‡å­—åˆ—æ“ä½œ
        complex_patterns = [
            r'eval\s*\(',
            r'exec\s*\(',
            r'\.replace\([^)]*\)',
            r'\.split\([^)]*\)'
        ]
        
        for pattern in complex_patterns:
            error_indicators += len(re.findall(pattern, code))
        
        # ç¢ºç‡ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
        probability = min(error_indicators * 0.1, 1.0)
        return probability
    
    async def _generate_suggestions(self, code: str, language: str, metrics: CodeQualityMetrics) -> List[str]:
        """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        suggestions = []
        
        if metrics.complexity_score > 7:
            suggestions.append("é–¢æ•°ã‚’ã‚ˆã‚Šå°ã•ãªé–¢æ•°ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if metrics.readability_score < 6:
            suggestions.append("ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦å¯èª­æ€§ã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„")
            suggestions.append("å¤‰æ•°åã‚’ã‚ˆã‚Šåˆ†ã‹ã‚Šã‚„ã™ãã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if metrics.maintainability_score < 6:
            suggestions.append("é‡è¤‡ã‚³ãƒ¼ãƒ‰ã‚’ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãã ã•ã„")
            suggestions.append("é–¢æ•°ã®ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if metrics.error_probability > 0.5:
            suggestions.append("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
            suggestions.append("å…¥åŠ›æ¤œè¨¼ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„")
        
        # è¨€èªå›ºæœ‰ã®ææ¡ˆ
        if language == 'python':
            if 'import *' in code:
                suggestions.append("ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã¦ã€å…·ä½“çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
            if not re.search(r'if\s+__name__\s*==\s*["\']__main__["\']', code):
                suggestions.append("if __name__ == '__main__': ã‚¬ãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        elif language == 'javascript':
            if 'var ' in code:
                suggestions.append("varã®ä»£ã‚ã‚Šã«letã‚„constã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
            if '==' in code and '===' not in code:
                suggestions.append("å³å¯†ç­‰ä¾¡æ¼”ç®—å­(===)ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        return suggestions


@injectable
class EnhancedProgramGenerator(BaseProgramGenerator):
    """AIçµ±åˆå¼·åŒ–ç‰ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆå™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.ollama_provider = OllamaProvider()
        self.rag_system = None
        self.prompt_manager = PromptTemplateManager()
        self.code_analyzer = EnhancedCodeAnalyzer()
        self.generation_history = []
        
        # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.default_params = {
            'temperature': 0.3,
            'max_tokens': 4000,
            'top_p': 0.9,
            'frequency_penalty': 0.1
        }
    
    async def initialize(self) -> bool:
        """å¼·åŒ–ç‰ˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–"""
        try:
            logger.info("Enhanced Program GeneratoråˆæœŸåŒ–é–‹å§‹...")
            
            # OllamaProvideråˆæœŸåŒ–
            if not await self.ollama_provider.initialize():
                logger.error("OllamaProvideråˆæœŸåŒ–å¤±æ•—")
                return False
            
            # RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            from config.config_manager import ConfigManager
            config_manager = ConfigManager()
            rag_config = await config_manager.get_config("rag_config.json")
            
            if rag_config:
                from ai.rag.rag_system import RAGSystem
                self.rag_system = RAGSystem(rag_config)
                await self.rag_system.initialize()
                logger.info("RAGã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Œäº†")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿
            await self.prompt_manager.load_templates()
            
            logger.info("Enhanced Program GeneratoråˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"Enhanced Program GeneratoråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def validate_input(self, job_input: JobInput) -> bool:
        """å¼·åŒ–ã•ã‚ŒãŸå…¥åŠ›æ¤œè¨¼"""
        try:
            # åŸºæœ¬æ¤œè¨¼
            if not job_input or not job_input.job_type:
                return False
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
            parameters = job_input.parameters or {}
            description = parameters.get('description', '')
            
            if not description or len(description.strip()) < 10:
                logger.warning("èª¬æ˜ãŒçŸ­ã™ãã¾ã™")
                return False
            
            # ä¸é©åˆ‡ãªå†…å®¹æ¤œå‡º
            inappropriate_keywords = [
                'virus', 'malware', 'hack', 'crack', 'illegal', 
                'piracy', 'exploit', 'backdoor'
            ]
            
            for keyword in inappropriate_keywords:
                if keyword.lower() in description.lower():
                    logger.warning(f"ä¸é©åˆ‡ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {keyword}")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"å…¥åŠ›æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def generate(self, job_input: JobInput) -> GenerationResult:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆ"""
        try:
            if not await self.validate_input(job_input):
                return GenerationResult(
                    success=False,
                    error_message="å…¥åŠ›æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ"
                )
            
            logger.info(f"å¼·åŒ–ç‰ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆé–‹å§‹: {job_input.job_id}")
            start_time = datetime.now()
            
            # è¤‡æ•°å›ã®ç”Ÿæˆè©¦è¡Œã§å“è³ªå‘ä¸Š
            best_result = None
            best_quality_score = 0.0
            
            for attempt in range(3):  # æœ€å¤§3å›è©¦è¡Œ
                try:
                    # ç”Ÿæˆå®Ÿè¡Œ
                    result = await self._generate_with_quality_check(job_input, attempt)
                    
                    if result.success:
                        # å“è³ªè©•ä¾¡
                        quality_score = await self._evaluate_generation_quality(result, job_input)
                        
                        if quality_score > best_quality_score:
                            best_result = result
                            best_quality_score = quality_score
                        
                        # ååˆ†ãªå“è³ªãªã‚‰çµ‚äº†
                        if quality_score >= 8.0:
                            break
                            
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆè©¦è¡Œ {attempt + 1} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            if not best_result:
                return GenerationResult(
                    success=False,
                    error_message="ã™ã¹ã¦ã®ç”Ÿæˆè©¦è¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸ"
                )
            
            # ç”Ÿæˆå±¥æ­´ã«è¨˜éŒ²
            generation_time = (datetime.now() - start_time).total_seconds()
            self._record_generation_history(job_input, best_result, generation_time, best_quality_score)
            
            logger.info(f"å¼·åŒ–ç‰ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆå®Œäº†: {job_input.job_id}, å“è³ªã‚¹ã‚³ã‚¢: {best_quality_score:.2f}")
            return best_result
            
        except Exception as e:
            logger.error(f"å¼·åŒ–ç‰ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return GenerationResult(
                success=False,
                error_message=f"ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            )
    
    async def _generate_with_quality_check(self, job_input: JobInput, attempt: int) -> GenerationResult:
        """å“è³ªãƒã‚§ãƒƒã‚¯ä»˜ãã®ç”Ÿæˆå®Ÿè¡Œ"""
        # é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        enhanced_prompt = await self._build_enhanced_prompt(job_input, attempt)
        
        # AIç”Ÿæˆå®Ÿè¡Œ
        generated_content = await self.ollama_provider.generate_text(
            prompt=enhanced_prompt,
            **self.default_params
        )
        
        # ã‚³ãƒ¼ãƒ‰æŠ½å‡º
        extracted_code = self._extract_code_from_response(generated_content)
        
        # å“è³ªåˆ†æ
        language = self._determine_content_type(job_input)
        quality_metrics = await self.code_analyzer.analyze_code_quality(extracted_code, language)
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        project_files = await self._create_enhanced_project_files(job_input, extracted_code, quality_metrics)
        
        # ZIPä½œæˆ
        zip_path = await self._create_zip_package(job_input.job_id, project_files)
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
        preview_html = await self._create_enhanced_preview(project_files, quality_metrics, language)
        
        return GenerationResult(
            success=True,
            content=extracted_code,
            files=project_files,
            download_url=zip_path,
            preview_html=preview_html,
            metadata={
                'language': language,
                'quality_metrics': quality_metrics.to_dict(),
                'generation_attempt': attempt + 1,
                'ai_model': self.ollama_provider.current_model,
                'prompt_length': len(enhanced_prompt),
                'code_length': len(extracted_code)
            }
        )
    
    async def _build_enhanced_prompt(self, job_input: JobInput, attempt: int) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        try:
            parameters = job_input.parameters
            description = parameters.get('description', '')
            language = self._determine_content_type(job_input)
            
            # ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            base_prompt = f"""ã‚ãªãŸã¯ç†Ÿç·´ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®è¦ä»¶ã«åŸºã¥ã„ã¦é«˜å“è³ªãª{language}ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## è¦ä»¶
{description}

## åˆ¶ç´„
- å®Ÿç”¨çš„ã§å‹•ä½œã™ã‚‹å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„
- é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã¦ãã ã•ã„  
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å«ã‚ã¦ãã ã•ã„
- å¯èª­æ€§ã¨ä¿å®ˆæ€§ã‚’é‡è¦–ã—ã¦ãã ã•ã„
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„
"""
            
            # RAGã‹ã‚‰ã®é–¢é€£æƒ…å ±ã‚’è¿½åŠ 
            if self.rag_system:
                rag_results = await self.rag_system.search(
                    query=f"{language} {description}",
                    mode="interactive",
                    top_k=3
                )
                
                if rag_results:
                    base_prompt += "\n## å‚è€ƒæƒ…å ±\n"
                    for result in rag_results:
                        base_prompt += f"- {result.chunk.content[:200]}...\n"
            
            # è¨€èªå›ºæœ‰ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
            guidelines = await self._get_language_guidelines(language)
            base_prompt += f"\n## {language}å›ºæœ‰ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³\n{guidelines}"
            
            # è©¦è¡Œå›æ•°ã«å¿œã˜ãŸèª¿æ•´
            if attempt > 0:
                base_prompt += f"\n\n## è¿½åŠ è¦æ±‚ï¼ˆè©¦è¡Œ {attempt + 1}ï¼‰\n"
                base_prompt += "å‰å›ã®ç”Ÿæˆçµæœã‚’æ”¹å–„ã—ã€ã‚ˆã‚Šé«˜å“è³ªãªã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
                base_prompt += "ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š\n"
                base_prompt += "- ã‚³ãƒ¼ãƒ‰ã®è¤‡é›‘åº¦ã‚’ä¸‹ã’ã‚‹\n"
                base_prompt += "- å¯èª­æ€§ã‚’å‘ä¸Šã•ã›ã‚‹\n"
                base_prompt += "- ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’å¼·åŒ–ã™ã‚‹\n"
            
            # å‡ºåŠ›å½¢å¼æŒ‡å®š
            base_prompt += f"\n\n## å‡ºåŠ›å½¢å¼\n```{language}\n[å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«è¨˜è¿°]\n```"
            
            return base_prompt
            
        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            return f"{language}ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„: {description}"
    
    async def _get_language_guidelines(self, language: str) -> str:
        """è¨€èªå›ºæœ‰ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³å–å¾—"""
        guidelines = {
            'python': """
- PEP 8ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦ãã ã•ã„
- å‹ãƒ’ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- docstringã‚’é©åˆ‡ã«è¨˜è¿°ã—ã¦ãã ã•ã„
- if __name__ == "__main__": ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- ä¾‹å¤–å‡¦ç†ã‚’é©åˆ‡ã«è¡Œã£ã¦ãã ã•ã„
""",
            'javascript': """
- ES6+ã®æ§‹æ–‡ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- const/letã‚’ä½¿ç”¨ã—ã€varã¯é¿ã‘ã¦ãã ã•ã„
- å³å¯†ç­‰ä¾¡æ¼”ç®—å­(===)ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¡Œã£ã¦ãã ã•ã„
- JSDocã‚³ãƒ¡ãƒ³ãƒˆã‚’è¨˜è¿°ã—ã¦ãã ã•ã„
""",
            'web': """
- ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãªHTMLã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
- é©åˆ‡ãªmetaã‚¿ã‚°ã‚’å«ã‚ã¦ãã ã•ã„
- CSSã¯å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯<style>ã‚¿ã‚°ã§è¨˜è¿°ã—ã¦ãã ã•ã„
"""
        }
        
        return guidelines.get(language, "å“è³ªã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
    
    async def _evaluate_generation_quality(self, result: GenerationResult, job_input: JobInput) -> float:
        """ç”Ÿæˆçµæœã®å“è³ªè©•ä¾¡"""
        try:
            if not result.success or not result.content:
                return 0.0
            
            # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‹ã‚‰åŸºæœ¬ã‚¹ã‚³ã‚¢è¨ˆç®—
            quality_metrics = result.metadata.get('quality_metrics', {})
            complexity_score = quality_metrics.get('complexity_score', 5.0)
            readability_score = quality_metrics.get('readability_score', 5.0)
            maintainability_score = quality_metrics.get('maintainability_score', 5.0)
            error_probability = quality_metrics.get('error_probability', 0.5)
            
            # åŸºæœ¬å“è³ªã‚¹ã‚³ã‚¢ï¼ˆ10ç‚¹æº€ç‚¹ï¼‰
            base_score = (
                (10 - complexity_score) * 0.3 +  # è¤‡é›‘åº¦ã¯ä½ã„æ–¹ãŒè‰¯ã„
                readability_score * 0.3 +
                maintainability_score * 0.3 +
                (1 - error_probability) * 10 * 0.1
            )
            
            # è¦ä»¶é”æˆåº¦è©•ä¾¡
            requirements_score = await self._evaluate_requirements_fulfillment(result, job_input)
            
            # æœ€çµ‚ã‚¹ã‚³ã‚¢è¨ˆç®—
            final_score = (base_score * 0.7) + (requirements_score * 0.3)
            
            return min(max(final_score, 0.0), 10.0)
            
        except Exception as e:
            logger.error(f"å“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return 5.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
    
    async def _evaluate_requirements_fulfillment(self, result: GenerationResult, job_input: JobInput) -> float:
        """è¦ä»¶é”æˆåº¦è©•ä¾¡"""
        try:
            description = job_input.parameters.get('description', '').lower()
            code = result.content.lower()
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
            keywords = re.findall(r'\b\w+\b', description)
            important_keywords = [kw for kw in keywords if len(kw) > 3]
            
            matches = 0
            for keyword in important_keywords:
                if keyword in code:
                    matches += 1
            
            # ãƒãƒƒãƒç‡ã‹ã‚‰è¦ä»¶é”æˆåº¦ã‚’è¨ˆç®—
            if important_keywords:
                match_ratio = matches / len(important_keywords)
                return min(match_ratio * 10, 10.0)
            
            return 7.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
        except Exception:
            return 7.0
    
    async def _create_enhanced_project_files(
        self, 
        job_input: JobInput, 
        code: str, 
        quality_metrics: CodeQualityMetrics
    ) -> List[Dict[str, Any]]:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        files = []
        language = self._determine_content_type(job_input)
        project_type = job_input.parameters.get('project_type', 'script')
        
        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
        main_filename = self._get_main_filename(project_type, language)
        files.append({
            'filename': main_filename,
            'content': code,
            'type': language,
            'line_count': len(code.split('\n')),
            'quality_score': (quality_metrics.complexity_score + quality_metrics.readability_score + quality_metrics.maintainability_score) / 3
        })
        
        # å¼·åŒ–ã•ã‚ŒãŸREADME.md
        readme_content = await self._generate_enhanced_readme(job_input, quality_metrics)
        files.append({
            'filename': 'README.md',
            'content': readme_content,
            'type': 'markdown',
            'line_count': len(readme_content.split('\n'))
        })
        
        # å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
        quality_report = await self._generate_quality_report(quality_metrics)
        files.append({
            'filename': 'QUALITY_REPORT.md',
            'content': quality_report,
            'type': 'markdown',
            'line_count': len(quality_report.split('\n'))
        })
        
        # è¨€èªå›ºæœ‰ãƒ•ã‚¡ã‚¤ãƒ«
        additional_files = await self._create_language_specific_files(job_input, code, language)
        files.extend(additional_files)
        
        return files
    
    async def _generate_enhanced_readme(self, job_input: JobInput, quality_metrics: CodeQualityMetrics) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸREADME.mdç”Ÿæˆ"""
        parameters = job_input.parameters
        description = parameters.get('description', '')
        language = self._determine_content_type(job_input)
        
        readme = f"""# {job_input.job_type.title()}

## æ¦‚è¦
{description}

## ç‰¹å¾´
- AIç”Ÿæˆã«ã‚ˆã‚‹é«˜å“è³ªãªã‚³ãƒ¼ãƒ‰
- å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ã
- è‡ªå‹•ãƒ†ã‚¹ãƒˆå¯¾å¿œ
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®æ¸ˆã¿

## å“è³ªæŒ‡æ¨™
- **è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢**: {quality_metrics.complexity_score:.1f}/10
- **å¯èª­æ€§ã‚¹ã‚³ã‚¢**: {quality_metrics.readability_score:.1f}/10
- **ä¿å®ˆæ€§ã‚¹ã‚³ã‚¢**: {quality_metrics.maintainability_score:.1f}/10
- **ã‚¨ãƒ©ãƒ¼äºˆæ¸¬ç¢ºç‡**: {quality_metrics.error_probability:.1%}

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
"""
        
        if language == 'python':
            readme += """
### Pythonç’°å¢ƒ
```bash
# ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv venv
source venv/bin/activate  # Windows: venv\\Scripts\\activate

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# å®Ÿè¡Œ
python main.py
```
"""
        elif language == 'javascript':
            readme += """
### Node.jsç’°å¢ƒ
```bash
# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
npm install

# å®Ÿè¡Œ
node main.js
```
"""
        elif language == 'web':
            readme += """
### Webç’°å¢ƒ
```bash
# é™çš„ã‚µãƒ¼ãƒãƒ¼ã§å®Ÿè¡Œ
python -m http.server 8000
# ã¾ãŸã¯
npx serve .
```
ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8000 ã«ã‚¢ã‚¯ã‚»ã‚¹
"""
        
        # æ”¹å–„ææ¡ˆè¿½åŠ 
        if quality_metrics.suggestions:
            readme += "\n## æ”¹å–„ææ¡ˆ\n"
            for i, suggestion in enumerate(quality_metrics.suggestions, 1):
                readme += f"{i}. {suggestion}\n"
        
        readme += f"""
## æŠ€è¡“ä»•æ§˜
- **è¨€èª**: {language.title()}
- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **AI ãƒ¢ãƒ‡ãƒ«**: Ollama (DeepSeek/Llama)
- **å“è³ªä¿è¨¼**: è‡ªå‹•åˆ†ææ¸ˆã¿

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
MIT License

## ã‚µãƒãƒ¼ãƒˆ
ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã«é–¢ã™ã‚‹è³ªå•ã‚„æ”¹å–„è¦æœ›ã¯ã€Support Systemã¾ã§ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚
"""
        
        return readme
    
    async def _generate_quality_report(self, quality_metrics: CodeQualityMetrics) -> str:
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = f"""# ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¬ãƒãƒ¼ãƒˆ

## ç”Ÿæˆæ—¥æ™‚
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹

### è¤‡é›‘åº¦ ({quality_metrics.complexity_score:.1f}/10)
"""
        
        if quality_metrics.complexity_score <= 3:
            report += "âœ… **å„ªç§€**: ã‚³ãƒ¼ãƒ‰ã¯éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ã§ç†è§£ã—ã‚„ã™ã„ã§ã™ã€‚"
        elif quality_metrics.complexity_score <= 6:
            report += "âš ï¸ **è‰¯å¥½**: é©åº¦ãªè¤‡é›‘ã•ã§ã™ãŒã€ã•ã‚‰ãªã‚‹ç°¡ç•¥åŒ–ãŒå¯èƒ½ã§ã™ã€‚"
        else:
            report += "âŒ **è¦æ”¹å–„**: ã‚³ãƒ¼ãƒ‰ãŒè¤‡é›‘ã™ãã¾ã™ã€‚ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
        
        report += f"""

### å¯èª­æ€§ ({quality_metrics.readability_score:.1f}/10)
"""
        
        if quality_metrics.readability_score >= 8:
            report += "âœ… **å„ªç§€**: ã‚³ãƒ¼ãƒ‰ã¯éå¸¸ã«èª­ã¿ã‚„ã™ãæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚"
        elif quality_metrics.readability_score >= 6:
            report += "âš ï¸ **è‰¯å¥½**: å¯èª­æ€§ã¯ååˆ†ã§ã™ãŒã€æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚"
        else:
            report += "âŒ **è¦æ”¹å–„**: å¯èª­æ€§ã®å‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚"
        
        report += f"""

### ä¿å®ˆæ€§ ({quality_metrics.maintainability_score:.1f}/10)
"""
        
        if quality_metrics.maintainability_score >= 8:
            report += "âœ… **å„ªç§€**: ä¿å®ˆã—ã‚„ã™ã„æ§‹é€ ã«ãªã£ã¦ã„ã¾ã™ã€‚"
        elif quality_metrics.maintainability_score >= 6:
            report += "âš ï¸ **è‰¯å¥½**: ä¿å®ˆæ€§ã¯ååˆ†ã§ã™ãŒã€æ”¹å–„å¯èƒ½ã§ã™ã€‚"
        else:
            report += "âŒ **è¦æ”¹å–„**: ä¿å®ˆæ€§ã®å‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚"
        
        report += f"""

### ã‚¨ãƒ©ãƒ¼äºˆæ¸¬ç¢ºç‡ ({quality_metrics.error_probability:.1%})
"""
        
        if quality_metrics.error_probability <= 0.2:
            report += "âœ… **ä½ãƒªã‚¹ã‚¯**: ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ã¯ä½ã„ã§ã™ã€‚"
        elif quality_metrics.error_probability <= 0.5:
            report += "âš ï¸ **ä¸­ãƒªã‚¹ã‚¯**: ä¸€éƒ¨ã®ã‚¨ãƒ©ãƒ¼ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚"
        else:
            report += "âŒ **é«˜ãƒªã‚¹ã‚¯**: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–ãŒå¿…è¦ã§ã™ã€‚"
        
        # æ”¹å–„ææ¡ˆ
        if quality_metrics.suggestions:
            report += "\n## æ”¹å–„ææ¡ˆ\n\n"
            for i, suggestion in enumerate(quality_metrics.suggestions, 1):
                report += f"{i}. **{suggestion}**\n"
        
        report += """
## ç·åˆè©•ä¾¡

ã“ã®å“è³ªãƒ¬ãƒãƒ¼ãƒˆã¯ã€AIã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’å®¢è¦³çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚
ææ¡ˆã•ã‚ŒãŸæ”¹å–„ç‚¹ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé«˜å“è³ªã§ä¿å®ˆã—ã‚„ã™ã„ã‚³ãƒ¼ãƒ‰ã«ãªã‚Šã¾ã™ã€‚

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ Enhanced Program Generator ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*
"""
        
        return report
    
    async def _create_language_specific_files(self, job_input: JobInput, code: str, language: str) -> List[Dict[str, Any]]:
        """è¨€èªå›ºæœ‰ã®è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        files = []
        
        if language == 'python':
            # requirements.txt
            requirements = await self._extract_python_requirements(code)
            if requirements:
                files.append({
                    'filename': 'requirements.txt',
                    'content': '\n'.join(requirements),
                    'type': 'text',
                    'line_count': len(requirements)
                })
            
            # pytestç”¨ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
            test_content = await self._generate_python_test(job_input, code)
            files.append({
                'filename': 'test_main.py',
                'content': test_content,
                'type': 'python',
                'line_count': len(test_content.split('\n'))
            })
            
        elif language == 'javascript':
            # package.json
            package_json = await self._generate_enhanced_package_json(job_input, code)
            files.append({
                'filename': 'package.json',
                'content': package_json,
                'type': 'json',
                'line_count': len(package_json.split('\n'))
            })
            
            # Jestç”¨ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
            test_content = await self._generate_javascript_test(job_input, code)
            files.append({
                'filename': 'main.test.js',
                'content': test_content,
                'type': 'javascript',
                'line_count': len(test_content.split('\n'))
            })
        
        return files
    
    async def _generate_python_test(self, job_input: JobInput, code: str) -> str:
        """Pythonç”¨ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        return f"""#!/usr/bin/env python3
\"\"\"
ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« - {job_input.job_type}
AIç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®è‡ªå‹•ãƒ†ã‚¹ãƒˆ
\"\"\"

import pytest
import unittest
from unittest.mock import Mock, patch

# ãƒ¡ã‚¤ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# import main  # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«å¿œã˜ã¦èª¿æ•´

class Test{job_input.job_type.title().replace('_', '')}(unittest.TestCase):
    \"\"\"ãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹\"\"\"
    
    def setUp(self):
        \"\"\"ãƒ†ã‚¹ãƒˆã®å‰å‡¦ç†\"\"\"
        pass
    
    def test_basic_functionality(self):
        \"\"\"åŸºæœ¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ\"\"\"
        # TODO: å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å®Ÿè£…
        self.assertTrue(True)
    
    def test_edge_cases(self):
        \"\"\"ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ\"\"\"
        # TODO: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…
        pass
    
    def test_error_handling(self):
        \"\"\"ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ\"\"\"
        # TODO: ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…
        pass

if __name__ == '__main__':
    unittest.main()
"""
    
    async def _generate_javascript_test(self, job_input: JobInput, code: str) -> str:
        """JavaScriptç”¨ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        return f"""/**
 * ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« - {job_input.job_type}
 * AIç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®è‡ªå‹•ãƒ†ã‚¹ãƒˆ
 */

const {{ describe, it, expect, beforeEach }} = require('@jest/globals');
// const main = require('./main'); // å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«å¿œã˜ã¦èª¿æ•´

describe('{job_input.job_type}', () => {{
    beforeEach(() => {{
        // ãƒ†ã‚¹ãƒˆã®å‰å‡¦ç†
    }});
    
    it('åŸºæœ¬æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹', () => {{
        // TODO: å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å®Ÿè£…
        expect(true).toBe(true);
    }});
    
    it('ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹', () => {{
        // TODO: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…
    }});
    
    it('ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹', () => {{
        // TODO: ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…
    }});
}});
"""
    
    async def _generate_enhanced_package_json(self, job_input: JobInput, code: str) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸpackage.jsonç”Ÿæˆ"""
        package_data = {
            "name": job_input.job_type.replace('_', '-'),
            "version": "1.0.0",
            "description": job_input.parameters.get('description', ''),
            "main": "main.js",
            "scripts": {
                "start": "node main.js",
                "test": "jest",
                "lint": "eslint *.js",
                "dev": "nodemon main.js"
            },
            "dependencies": await self._extract_js_dependencies(code),
            "devDependencies": {
                "jest": "^29.0.0",
                "eslint": "^8.0.0",
                "nodemon": "^2.0.0"
            },
            "keywords": ["ai-generated", "javascript"],
            "author": "Enhanced Program Generator",
            "license": "MIT"
        }
        
        return json.dumps(package_data, indent=2, ensure_ascii=False)
    
    async def _create_enhanced_preview(self, project_files: List[Dict[str, Any]], quality_metrics: CodeQualityMetrics, language: str) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ"""
        try:
            main_file = next((f for f in project_files if f['filename'].endswith(('.py', '.js', '.html'))), None)
            
            if not main_file:
                return "<p>ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚</p>"
            
            # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
            overall_quality = (
                quality_metrics.complexity_score + 
                quality_metrics.readability_score + 
                quality_metrics.maintainability_score
            ) / 3
            
            quality_color = "green" if overall_quality >= 7 else "orange" if overall_quality >= 5 else "red"
            
            preview = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Enhanced Code Preview - {main_file['filename']}</title>
    <style>
        body {{ 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; padding: 20px; 
            background: #f5f5f5; 
        }}
        .container {{ 
            max-width: 1200px; 
            margin: 0 auto; 
            background: white; 
            border-radius: 10px; 
            overflow: hidden; 
            box-shadow: 0 4px 6px rgba(0,0,0,0.1); 
        }}
        .header {{ 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            color: white; 
            padding: 30px; 
            text-align: center; 
        }}
        .quality-badge {{ 
            display: inline-block; 
            padding: 5px 15px; 
            background: {quality_color}; 
            color: white; 
            border-radius: 20px; 
            font-size: 14px; 
            margin-top: 10px; 
        }}
        .metrics {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); 
            gap: 20px; 
            padding: 30px; 
            background: #f8f9fa; 
        }}
        .metric {{ 
            background: white; 
            padding: 20px; 
            border-radius: 8px; 
            text-align: center; 
            box-shadow: 0 2px 4px rgba(0,0,0,0.1); 
        }}
        .metric-value {{ 
            font-size: 2em; 
            font-weight: bold; 
            color: #667eea; 
            margin-bottom: 5px; 
        }}
        .code-section {{ 
            padding: 30px; 
        }}
        .code {{ 
            background: #2d3748; 
            color: #e2e8f0; 
            padding: 20px; 
            border-radius: 8px; 
            overflow-x: auto; 
            font-family: 'Consolas', 'Monaco', monospace; 
            line-height: 1.5; 
        }}
        .suggestions {{ 
            padding: 30px; 
            background: #fff3cd; 
        }}
        .suggestion {{ 
            background: white; 
            padding: 15px; 
            margin: 10px 0; 
            border-left: 4px solid #ffc107; 
            border-radius: 4px; 
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Enhanced Code Preview</h1>
            <p>{main_file['filename']} | {language.title()}</p>
            <div class="quality-badge">å“è³ªã‚¹ã‚³ã‚¢: {overall_quality:.1f}/10</div>
        </div>
        
        <div class="metrics">
            <div class="metric">
                <div class="metric-value">{quality_metrics.complexity_score:.1f}</div>
                <div>è¤‡é›‘åº¦</div>
            </div>
            <div class="metric">
                <div class="metric-value">{quality_metrics.readability_score:.1f}</div>
                <div>å¯èª­æ€§</div>
            </div>
            <div class="metric">
                <div class="metric-value">{quality_metrics.maintainability_score:.1f}</div>
                <div>ä¿å®ˆæ€§</div>
            </div>
            <div class="metric">
                <div class="metric-value">{quality_metrics.error_probability:.0%}</div>
                <div>ã‚¨ãƒ©ãƒ¼äºˆæ¸¬ç¢ºç‡</div>
            </div>
        </div>
        
        <div class="code-section">
            <h3>ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰</h3>
            <pre class="code">{self._escape_html(main_file['content'])}</pre>
        </div>
"""
            
            if quality_metrics.suggestions:
                preview += """
        <div class="suggestions">
            <h3>æ”¹å–„ææ¡ˆ</h3>
"""
                for suggestion in quality_metrics.suggestions:
                    preview += f'<div class="suggestion">ğŸ’¡ {suggestion}</div>'
                
                preview += "</div>"
            
            preview += """
    </div>
</body>
</html>"""
            
            return preview
            
        except Exception as e:
            logger.error(f"å¼·åŒ–ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return f"<p>ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}</p>"
    
    async def _extract_python_requirements(self, code: str) -> List[str]:
        """Pythonè¦ä»¶æŠ½å‡ºï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        requirements = set()
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æŠ½å‡º
        import_patterns = [
            r'^import\s+([a-zA-Z_][a-zA-Z0-9_]*)',
            r'^from\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+import'
        ]
        
        for pattern in import_patterns:
            matches = re.findall(pattern, code, re.MULTILINE)
            requirements.update(matches)
        
        # æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’é™¤å¤–
        stdlib_modules = {
            'os', 'sys', 'json', 'csv', 're', 'math', 'datetime', 'time',
            'random', 'collections', 'itertools', 'functools', 'operator',
            'urllib', 'http', 'email', 'html', 'xml', 'sqlite3', 'pickle',
            'base64', 'hashlib', 'hmac', 'secrets', 'ssl', 'socket',
            'threading', 'asyncio', 'multiprocessing', 'subprocess',
            'pathlib', 'shutil', 'tempfile', 'glob', 'fnmatch',
            'unittest', 'typing', 'enum', 'dataclasses', 'abc'
        }
        
        external_requirements = requirements - stdlib_modules
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®šä»˜ãã§è¿”ã™
        versioned_requirements = []
        version_map = {
            'numpy': 'numpy>=1.21.0',
            'pandas': 'pandas>=1.3.0',
            'matplotlib': 'matplotlib>=3.5.0',
            'seaborn': 'seaborn>=0.11.0',
            'scipy': 'scipy>=1.7.0',
            'scikit-learn': 'scikit-learn>=1.0.0',
            'sklearn': 'scikit-learn>=1.0.0',
            'tensorflow': 'tensorflow>=2.8.0',
            'torch': 'torch>=1.10.0',
            'cv2': 'opencv-python>=4.5.0',
            'PIL': 'Pillow>=8.0.0',
            'requests': 'requests>=2.25.0',
            'flask': 'Flask>=2.0.0',
            'django': 'Django>=4.0.0',
            'fastapi': 'fastapi>=0.70.0',
            'pydantic': 'pydantic>=1.8.0',
            'sqlalchemy': 'SQLAlchemy>=1.4.0'
        }
        
        for req in sorted(external_requirements):
            versioned_requirements.append(version_map.get(req, req))
        
        return versioned_requirements
    
    async def _extract_js_dependencies(self, code: str) -> Dict[str, str]:
        """JavaScriptä¾å­˜é–¢ä¿‚æŠ½å‡ºï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        dependencies = {}
        
        # requireæ–‡ã‚’æŠ½å‡º
        require_pattern = r'require\s*\(\s*["\']([^"\']+)["\']\s*\)'
        requires = re.findall(require_pattern, code)
        
        # importæ–‡ã‚’æŠ½å‡º
        import_pattern = r'import\s+.*?\s+from\s+["\']([^"\']+)["\']'
        imports = re.findall(import_pattern, code)
        
        all_modules = set(requires + imports)
        
        # Node.jsæ¨™æº–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é™¤å¤–
        stdlib_modules = {
            'fs', 'path', 'os', 'crypto', 'http', 'https', 'url',
            'querystring', 'util', 'events', 'stream', 'buffer',
            'process', 'child_process', 'cluster', 'net', 'dns',
            'assert', 'console', 'timers', 'readline', 'repl'
        }
        
        external_modules = [mod for mod in all_modules if mod not in stdlib_modules and not mod.startswith('.')]
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®š
        version_map = {
            'express': '^4.18.0',
            'lodash': '^4.17.0',
            'axios': '^0.27.0',
            'moment': '^2.29.0',
            'uuid': '^8.3.0',
            'joi': '^17.6.0',
            'bcrypt': '^5.0.0',
            'jsonwebtoken': '^8.5.0',
            'mongoose': '^6.3.0',
            'sequelize': '^6.20.0',
            'react': '^18.1.0',
            'vue': '^3.2.0',
            'angular': '^14.0.0'
        }
        
        for module in external_modules:
            dependencies[module] = version_map.get(module, '^1.0.0')
        
        return dependencies
    
    def _record_generation_history(self, job_input: JobInput, result: GenerationResult, generation_time: float, quality_score: float):
        """ç”Ÿæˆå±¥æ­´ã®è¨˜éŒ²"""
        history_entry = {
            'timestamp': datetime.now().isoformat(),
            'job_id': job_input.job_id,
            'job_type': job_input.job_type,
            'language': result.metadata.get('language', 'unknown'),
            'quality_score': quality_score,
            'generation_time': generation_time,
            'code_length': len(result.content),
            'file_count': len(result.files),
            'success': result.success
        }
        
        self.generation_history.append(history_entry)
        
        # å±¥æ­´ã¯æœ€æ–°100ä»¶ã¾ã§ä¿æŒ
        if len(self.generation_history) > 100:
            self.generation_history = self.generation_history[-100:]
        
        logger.info(f"ç”Ÿæˆå±¥æ­´è¨˜éŒ²: å“è³ªã‚¹ã‚³ã‚¢ {quality_score:.2f}, æ™‚é–“ {generation_time:.2f}ç§’")
    
    async def get_generation_statistics(self) -> Dict[str, Any]:
        """ç”Ÿæˆçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.generation_history:
            return {"message": "ç”Ÿæˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        total_generations = len(self.generation_history)
        successful_generations = sum(1 for entry in self.generation_history if entry['success'])
        
        quality_scores = [entry['quality_score'] for entry in self.generation_history if entry['success']]
        generation_times = [entry['generation_time'] for entry in self.generation_history if entry['success']]
        
        statistics = {
            'total_generations': total_generations,
            'successful_generations': successful_generations,
            'success_rate': successful_generations / total_generations if total_generations > 0 else 0,
            'average_quality_score': sum(quality_scores) / len(quality_scores) if quality_scores else 0,
            'average_generation_time': sum(generation_times) / len(generation_times) if generation_times else 0,
            'languages_used': list(set(entry['language'] for entry in self.generation_history)),
            'most_common_job_type': max(set(entry['job_type'] for entry in self.generation_history), 
                                      key=lambda x: sum(1 for e in self.generation_history if e['job_type'] == x)) if self.generation_history else None
        }
        
        return statistics
    
    async def cleanup_old_files(self, days: int = 7):
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            import glob
            from datetime import timedelta
            
            cutoff_date = datetime.now() - timedelta(days=days)
            
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            temp_pattern = os.path.join(self.output_dir, "project_*")
            for temp_dir in glob.glob(temp_pattern):
                try:
                    dir_stat = os.path.stat(temp_dir)
                    if datetime.fromtimestamp(dir_stat.st_mtime) < cutoff_date:
                        shutil.rmtree(temp_dir)
                        logger.info(f"å¤ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤: {temp_dir}")
                except Exception as e:
                    logger.warning(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {temp_dir}, {e}")
            
            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            zip_pattern = os.path.join(self.output_dir, "*.zip")
            for zip_file in glob.glob(zip_pattern):
                try:
                    file_stat = os.path.stat(zip_file)
                    if datetime.fromtimestamp(file_stat.st_mtime) < cutoff_date:
                        os.remove(zip_file)
                        logger.info(f"å¤ã„ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {zip_file}")
                except Exception as e:
                    logger.warning(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {zip_file}, {e}")
            
            logger.info(f"{days}æ—¥ä»¥ä¸Šå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")